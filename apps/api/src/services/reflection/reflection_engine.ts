/**
 * Reflection Engine
 * 
 * Generates a structured reflection for a completed run.
 * Uses prompts/reflection.md format.
 * 
 * Reflection is READ-ONLY — it does not change state.
 */

import type { RunTimeline } from "./timeline_builder.js";
import type { ImprovementReport } from "./improvement_analyzer.js";
import type { TestPlan, TestPlanStep } from "../decision/types.js";
// =============================================================================
// Reflection Schema
// =============================================================================

export interface RunReflection {
  run_id: string;
  /** What NOEMA observed */
  what_observed: string[];
  /** What it believed */
  what_believed: string[];
  /** What it tried */
  what_tried: string[];
  /** What worked better */
  what_worked_better: string[];
  /** What it learned */
  what_learned: string[];
  /** How it improved compared to earlier runs */
  improvement_summary: string;
  /** Open questions remaining */
  open_questions: string[];
  /** Next best action suggestion */
  next_best_action: string;
  /** Generated at */
  timestamp: string;
}

// =============================================================================
// QA Report Schema
// =============================================================================

/** A single test step in the QA report */
export interface QATestStep {
  /** Step number (1-based) */
  step: number;
  /** Action type that was performed */
  action_type: string;
  /** What NOEMA intended to do */
  description: string;
  /** Result of this step */
  result: "pass" | "fail";
  /** Duration in ms */
  duration_ms: number;
  /** Error message if failed */
  error?: string;
  /** Screenshot path if captured */
  screenshot?: string;
  /** Timestamp */
  timestamp: string;
}

/** Plan step result in the report (serializable) */
export interface QAPlanStep {
  /** Step number (1-based) */
  step_id: number;
  /** Short title */
  title: string;
  /** Description of what to test */
  description: string;
  /** Ordered sub-steps within this test case */
  test_steps?: string[];
  /** Specific expected results */
  expected_results?: string[];
  /** Priority level */
  priority: "critical" | "important" | "nice_to_have";
  /** What was expected */
  expected_outcome: string;
  /** What actually happened */
  actual_outcome: string;
  /** Result */
  result: "pass" | "fail" | "skipped";
  /** Actions taken for this step */
  actions_taken: number;
  /** Screenshot URLs for this step (relative API paths) */
  screenshot_urls?: string[];
}

/** Plan summary in the report */
export interface QAPlan {
  /** Plan title */
  plan_title: string;
  /** Why the plan was structured this way */
  plan_rationale: string;
  /** Total planned steps */
  total_steps: number;
  /** Passed steps */
  passed: number;
  /** Failed steps */
  failed: number;
  /** Skipped steps */
  skipped: number;
  /** Whether generated by LLM or built-in rule engine */
  generated_by: "gemini" | "built_in";
  /** Individual plan steps with results */
  steps: QAPlanStep[];
}

export interface QAReport {
  /** Run ID */
  run_id: string;
  /** Test title (human readable) */
  test_title: string;
  /** Test description */
  test_description: string;
  /** Original task (raw) */
  task: string;
  /** Target URL */
  target_url: string;
  /** Overall result */
  result: "pass" | "fail" | "partial";
  /** Summary of findings */
  summary: string;
  /** The test plan that was generated and executed */
  plan: QAPlan;
  /** Ordered test steps with individual pass/fail */
  test_steps: QATestStep[];
  /** Pass count */
  passed_steps: number;
  /** Fail count */
  failed_steps: number;
  /** Detailed reflection */
  reflection: RunReflection;
  /** Improvement report */
  improvement: ImprovementReport;
  /** Identity context */
  identity_statement: string;
  /** Timeline entries count */
  total_events: number;
  /** Actions taken */
  actions_taken: number;
  /** Observations created */
  observations_created: number;
  /** Models affected */
  models_affected: number;
  /** Experiences learned */
  experiences_learned: number;
  /** Duration */
  duration_ms: number;
  /** Generated at */
  timestamp: string;
  /** URL to the full run video recording (if available) */
  video_url?: string;
  /** Persistent Memory → LLM Savings */
  memory_savings?: {
    llm_calls_made: number;
    llm_calls_saved: number;
    plan_reused: boolean;
    steps_from_memory: number;
    savings_percent: number;
  };
}

// =============================================================================
// Reflection Generation (No LLM — deterministic from state)
// =============================================================================

/**
 * Generate a structured reflection from a run timeline and improvement report.
 */
export function generateReflection(
  runId: string,
  timeline: RunTimeline,
  improvement: ImprovementReport
): RunReflection {
  const observations = timeline.entries.filter((e) => e.type === "observation");
  const actions = timeline.entries.filter((e) => e.type === "action");
  const outcomes = timeline.entries.filter((e) => e.type === "outcome");
  const beliefUpdates = timeline.entries.filter((e) => e.type === "belief_update");
  const experiencesLearned = timeline.entries.filter((e) => e.type === "experience_learned");

  // What NOEMA observed
  const whatObserved = observations.map((o) => o.summary);

  // What it believed
  const whatBelieved = beliefUpdates.map((b) => b.summary);

  // What it tried
  const whatTried = actions.map((a) => a.summary);

  // What worked better
  const successfulOutcomes = outcomes.filter((o) => (o.details as any).success === true);
  const failedOutcomes = outcomes.filter((o) => (o.details as any).success === false);
  const whatWorkedBetter: string[] = [];

  if (successfulOutcomes.length > 0) {
    whatWorkedBetter.push(
      `${successfulOutcomes.length} action(s) succeeded out of ${outcomes.length} total`
    );
  }

  if (improvement.signals.some((s) => s.direction === "improved")) {
    for (const signal of improvement.signals.filter((s) => s.direction === "improved")) {
      whatWorkedBetter.push(signal.description);
    }
  }

  // What it learned
  const whatLearned = experiencesLearned.map((e) => e.summary);
  if (whatLearned.length === 0 && failedOutcomes.length > 0) {
    whatLearned.push("Observed failures that may inform future actions.");
  }

  // Improvement summary
  const improvementSummary = improvement.conclusion;

  // Open questions
  const openQuestions: string[] = [];
  if (failedOutcomes.length > 0) {
    openQuestions.push("Why did some actions fail? Could different approaches be tried?");
  }
  if (beliefUpdates.length === 0) {
    openQuestions.push("No beliefs were updated in this run. Was the evidence insufficient?");
  }

  // Next best action
  let nextBestAction = "Continue monitoring and running similar tasks to accumulate more experience.";
  if (failedOutcomes.length > failedOutcomes.length / 2) {
    nextBestAction = "Re-run with different action strategies to find more reliable approaches.";
  }

  return {
    run_id: runId,
    what_observed: whatObserved,
    what_believed: whatBelieved,
    what_tried: whatTried,
    what_worked_better: whatWorkedBetter,
    what_learned: whatLearned,
    improvement_summary: improvementSummary,
    open_questions: openQuestions,
    next_best_action: nextBestAction,
    timestamp: new Date().toISOString(),
  };
}

/**
 * Generate a full QA report for a run.
 */
/**
 * Convert a file-system screenshot path to a relative API URL.
 * e.g. "./data/screenshots/abc_1_123.png" → "/evidence/screenshots/abc_1_123.png"
 */
function screenshotPathToUrl(filePath: string): string {
  const filename = filePath.split("/").pop() || filePath;
  return `/evidence/screenshots/${filename}`;
}

export function generateQAReport(
  runId: string,
  task: string,
  timeline: RunTimeline,
  reflection: RunReflection,
  improvement: ImprovementReport,
  identityStatement: string,
  targetUrl?: string,
  testPlan?: TestPlan,
  videoPath?: string | null,
  memorySavings?: {
    llm_calls_made: number;
    llm_calls_saved: number;
    plan_reused: boolean;
    steps_from_memory: number;
  }
): QAReport {
  const actions = timeline.entries.filter((e) => e.type === "action");
  const observations = timeline.entries.filter((e) => e.type === "observation");
  const outcomes = timeline.entries.filter((e) => e.type === "outcome");
  const beliefUpdates = timeline.entries.filter((e) => e.type === "belief_update");
  const experiencesLearned = timeline.entries.filter((e) => e.type === "experience_learned");

  // ─── Derive pass/fail from plan steps (authoritative) ───────────
  const planPassed = testPlan ? testPlan.steps.filter((s) => s.result === "pass").length : 0;
  const planFailed = testPlan ? testPlan.steps.filter((s) => s.result === "fail").length : 0;
  const planSkipped = testPlan ? testPlan.steps.filter((s) => s.result === "skipped" || !s.result).length : 0;

  // Fallback to timeline outcomes only if no plan
  const successCount = testPlan ? planPassed : outcomes.filter((o) => (o.details as any).success === true).length;
  const failureCount = testPlan ? planFailed : outcomes.filter((o) => (o.details as any).success === false).length;

  let result: "pass" | "fail" | "partial";
  if (failureCount === 0 && successCount > 0) {
    result = "pass";
  } else if (successCount === 0 && failureCount === 0) {
    result = planSkipped > 0 ? "partial" : "fail";
  } else if (successCount === 0) {
    result = "fail";
  } else {
    result = "partial";
  }

  // ─── Build test steps from plan steps (not broken timeline) ─────
  const testSteps: QATestStep[] = [];
  if (testPlan) {
    for (const planStep of testPlan.steps) {
      testSteps.push({
        step: planStep.step_id,
        action_type: planStep.title,
        description: planStep.description,
        result: planStep.result === "pass" ? "pass" : "fail",
        duration_ms: 0,
        error: planStep.result === "fail" ? (planStep.actual_outcome || "Step did not complete successfully") : undefined,
        screenshot: planStep.screenshots?.[0] ? screenshotPathToUrl(planStep.screenshots[0]) : undefined,
        timestamp: new Date().toISOString(),
      });
    }
  } else {
    // Legacy fallback: timeline-based test steps
    let stepNumber = 0;
    for (const action of actions) {
      stepNumber++;
      const matchingOutcome = outcomes.find(
        (o) => (o.details as any).action_id === (action.details as any).action_id
      );
      const success = matchingOutcome ? (matchingOutcome.details as any).success === true : false;
      testSteps.push({
        step: stepNumber,
        action_type: (action.details as any).type || "unknown",
        description: action.summary.replace(/^Action:\s*/, ""),
        result: success ? "pass" : "fail",
        duration_ms: matchingOutcome
          ? new Date(matchingOutcome.timestamp).getTime() - new Date(action.timestamp).getTime()
          : 0,
        error: !success && matchingOutcome
          ? matchingOutcome.summary.replace(/^Outcome:\s*/, "")
          : undefined,
        screenshot: undefined,
        timestamp: action.timestamp,
      });
    }
  }

  // Generate human-readable title and description
  const testTitle = generateTestTitle(task);
  const testDescription = generateTestDescription(task, targetUrl);

  const summary = [
    `${result.toUpperCase()}: ${testTitle}`,
    testPlan ? `${testPlan.total_steps} test steps executed` : `${actions.length} actions executed`,
    `${planPassed || successCount} passed, ${planFailed || failureCount} failed`,
    `${observations.length} observations, ${beliefUpdates.length} belief updates`,
    `${experiencesLearned.length} new experiences learned`,
    improvement.has_improved ? "Performance improved vs. previous runs" : "",
  ].filter(Boolean).join(" · ");

  // Build plan summary for the report
  const planSummary: QAPlan = testPlan
    ? {
        plan_title: testPlan.plan_title,
        plan_rationale: testPlan.plan_rationale,
        total_steps: testPlan.total_steps,
        passed: testPlan.steps.filter((s) => s.result === "pass").length,
        failed: testPlan.steps.filter((s) => s.result === "fail").length,
        skipped: testPlan.steps.filter((s) => s.result === "skipped").length,
        generated_by: testPlan.generated_by,
        steps: testPlan.steps.map((s) => ({
          step_id: s.step_id,
          title: s.title,
          description: s.description,
          test_steps: s.test_steps,
          expected_results: s.expected_results,
          priority: s.priority,
          expected_outcome: s.expected_outcome,
          actual_outcome: s.actual_outcome || "",
          result: s.result || "skipped",
          actions_taken: s.actions_taken || 0,
          screenshot_urls: (s.screenshots || []).map(screenshotPathToUrl),
        })),
      }
    : {
        plan_title: "No plan generated",
        plan_rationale: "",
        total_steps: 0,
        passed: 0,
        failed: 0,
        skipped: 0,
        generated_by: "built_in" as const,
        steps: [],
      };

  return {
    run_id: runId,
    test_title: testTitle,
    test_description: testDescription,
    task,
    target_url: targetUrl || "",
    result,
    summary,
    plan: planSummary,
    test_steps: testSteps,
    passed_steps: planPassed || successCount,
    failed_steps: planFailed || failureCount,
    reflection,
    improvement,
    identity_statement: identityStatement,
    total_events: timeline.entries.length,
    actions_taken: actions.length,
    observations_created: observations.length,
    models_affected: beliefUpdates.length,
    experiences_learned: experiencesLearned.length,
    duration_ms: timeline.duration_ms,
    timestamp: new Date().toISOString(),
    video_url: videoPath ? `/evidence/videos/${videoPath.split("/").pop()}` : undefined,
    memory_savings: memorySavings ? {
      ...memorySavings,
      savings_percent: (memorySavings.llm_calls_made + memorySavings.llm_calls_saved) > 0
        ? (memorySavings.llm_calls_saved / (memorySavings.llm_calls_made + memorySavings.llm_calls_saved)) * 100
        : 0,
    } : undefined,
  };
}

/**
 * Generate a human-readable test title from the task description.
 */
function generateTestTitle(task: string): string {
  // Capitalize first letter, truncate to first sentence
  const firstSentence = task.split(/[.!?]/)[0].trim();
  const title = firstSentence.charAt(0).toUpperCase() + firstSentence.slice(1);
  return title.length > 80 ? title.substring(0, 77) + "..." : title;
}

/**
 * Generate a test description from the task and URL.
 */
function generateTestDescription(task: string, url?: string): string {
  const parts: string[] = [];
  parts.push(`Automated QA test: ${task}`);
  if (url) {
    parts.push(`Target: ${url}`);
  }
  return parts.join("\n");
}
